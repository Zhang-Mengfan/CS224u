{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch_model_base import TorchModelBase\n",
    "from torch_rnn_classifier import TorchRNNClassifier, TorchRNNClassifierModel\n",
    "from torch_rnn_classifier import TorchRNNClassifier\n",
    "import nli\n",
    "import os\n",
    "import utils\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_HOME = \"/home/brett_szalapski/\"\n",
    "\n",
    "DATA_HOME = \"/Users/bszalapski/Documents/StanfordCourses/CS224U/cs224u_project/cs224uSNLI/data\"\n",
    "\n",
    "SNLI_HOME = os.path.join(DATA_HOME, \"nlidata/snli_1.0\")\n",
    "\n",
    "MULTINLI_HOME = os.path.join(DATA_HOME, \"multinli_1.0\")\n",
    "\n",
    "ANNOTATIONS_HOME = os.path.join(DATA_HOME, \"multinli_1.0_annotations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reader = nli.SNLITrainReader(\n",
    "    SNLI_HOME, samp_percentage=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_softmax_classifier_with_preselected_params(X, y):       \n",
    "    mod = LogisticRegression(\n",
    "        fit_intercept=True, \n",
    "        penalty='l1', \n",
    "        solver='saga',  ## Required for penalty='ll'.\n",
    "        multi_class='ovr',\n",
    "        C=0.4)\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare SRL and glove embedding lookups\n",
    "# from allennlp.predictors.predictor import Predictor\n",
    "# predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/srl-model-2018.05.25.tar.gz\")\n",
    "\n",
    "srl_lookup = {}\n",
    "\n",
    "glove_dim = 50\n",
    "glove_lookup = utils.glove2dict(\n",
    "    os.path.join(GLOVE_HOME, 'glove.6B.50d.txt'))\n",
    "glove_lookup[\"$UNK\"] = utils.randvec(n=glove_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_leaves_phi(t1, t2, np_func=np.concatenate):\n",
    "# def glove_leaves_phi(ex, np_func=np.concatenate):\n",
    "    \"\"\"Represent `tree` as a combination of the vector of its words.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t1 : nltk.Tree   \n",
    "    t2 : nltk.Tree   \n",
    "    np_func : function (default: np.sum)\n",
    "        A numpy matrix operation that can be applied columnwise, \n",
    "        like `np.mean`, `np.sum`, or `np.prod`. The requirement is that \n",
    "        the function take `axis=0` as one of its arguments (to ensure\n",
    "        columnwise combination) and that it return a vector of a \n",
    "        fixed length, no matter what the size of the tree is.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "            \n",
    "    \"\"\"\n",
    "    if hasattr(t1, \"leaves\"):\n",
    "        s1 = t1.leaves()\n",
    "        s2 = t2.leaves()\n",
    "    else:\n",
    "        s1 = t1\n",
    "        s2 = t2\n",
    "    tags = predictor.predict_batch_json([{\"sentence\": \" \".join(s1)}, {\"sentence\": \" \".join(s2)}])\n",
    "    \n",
    "    prem_tags = _get_best_tags(tags[0], np_func)\n",
    "    hyp_tags = _get_best_tags(tags[1], np_func)\n",
    "#     print(f\"{ex.sentence1}, {ex.sentence2}\")\n",
    "#     prem_tags = _embed_tags(ex.tags1, np_func)\n",
    "#     hyp_tags = _embed_tags(ex.tags2, np_func)\n",
    "    prem_tags_tens = torch.tensor(prem_tags, requires_grad=True)\n",
    "    hyp_tags_tens = torch.tensor(hyp_tags, requires_grad=True)\n",
    "#     print(prem_tags_tens.size())\n",
    "    \n",
    "    prem_words = _get_tree_vecs(t1, glove_lookup, np_func)\n",
    "    hyp_words = _get_tree_vecs(t2, glove_lookup, np_func)\n",
    "    prem_words_tens = torch.tensor(prem_words, requires_grad=False)\n",
    "#     print(prem_words_tens.size())\n",
    "    hyp_words_tens = torch.tensor(hyp_words, requires_grad=False)\n",
    "    \n",
    "    prem_vecs = torch.cat((prem_words_tens, prem_tags_tens))\n",
    "    hyp_vecs = torch.cat((hyp_words_tens, hyp_tags_tens))\n",
    "    \n",
    "    return (prem_vecs, hyp_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSentenceEncoderDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, seq_lengths, y):\n",
    "        self.prem_seqs, self.hyp_seqs = sequences\n",
    "        self.prem_lengths, self.hyp_lengths = seq_lengths\n",
    "        self.y = y\n",
    "        assert len(self.prem_seqs) == len(self.y)\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        X_prem, X_hyp, prem_lengths, hyp_lengths, y = zip(*batch)\n",
    "        prem_lengths = torch.LongTensor(prem_lengths)\n",
    "        hyp_lengths = torch.LongTensor(hyp_lengths)\n",
    "        y = torch.LongTensor(y)\n",
    "        return (X_prem, X_hyp), (prem_lengths, hyp_lengths), y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prem_seqs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.prem_seqs[idx], self.hyp_seqs[idx],\n",
    "                self.prem_lengths[idx], self.hyp_lengths[idx],\n",
    "                self.y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSentenceEncoderClassifierModel(TorchRNNClassifierModel):\n",
    "    def __init__(self, vocab_size, embed_dim, embedding, use_embedding,\n",
    "            hidden_dim, output_dim, bidirectional, device):\n",
    "        super(TorchRNNSentenceEncoderClassifierModel, self).__init__(\n",
    "            vocab_size, embed_dim, embedding, use_embedding,\n",
    "            hidden_dim, output_dim, bidirectional, device)\n",
    "        self.hypothesis_rnn = nn.LSTM(\n",
    "            input_size=2 * glove_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True,\n",
    "            bidirectional=self.bidirectional)\n",
    "        if bidirectional:\n",
    "            classifier_dim = hidden_dim * 2 * 2\n",
    "        else:\n",
    "            classifier_dim = hidden_dim * 2\n",
    "        self.classifier_layer = nn.Linear(\n",
    "            classifier_dim, output_dim)\n",
    "\n",
    "    def forward(self, X, seq_lengths):\n",
    "        X_prem, X_hyp = X\n",
    "        prem_lengths, hyp_lengths = seq_lengths\n",
    "        \n",
    "        prem_state = self.rnn_forward(X_prem, prem_lengths, self.rnn)\n",
    "        hyp_state = self.rnn_forward(X_hyp, hyp_lengths, self.hypothesis_rnn)\n",
    "        state = torch.cat((prem_state, hyp_state), dim=1)\n",
    "        logits = self.classifier_layer(state)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchRNNSentenceEncoderClassifier(TorchRNNClassifier):\n",
    "\n",
    "    def build_dataset(self, X, y):\n",
    "        X_prem, X_hyp = zip(*X)\n",
    "        X_prem, prem_lengths = self._prepare_dataset(X_prem)\n",
    "        X_hyp, hyp_lengths = self._prepare_dataset(X_hyp)\n",
    "        return TorchRNNSentenceEncoderDataset(\n",
    "            (X_prem, X_hyp), (prem_lengths, hyp_lengths), y)\n",
    "\n",
    "    def build_graph(self):\n",
    "        return TorchRNNSentenceEncoderClassifierModel(\n",
    "            len(self.vocab),\n",
    "            embedding=self.embedding,\n",
    "            embed_dim=2 * glove_dim,\n",
    "            use_embedding=self.use_embedding,\n",
    "            hidden_dim=self.hidden_dim,\n",
    "            output_dim=self.n_classes_,\n",
    "            bidirectional=self.bidirectional,\n",
    "            device=self.device\n",
    "        )\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        with torch.no_grad():\n",
    "            X_prem, X_hyp = zip(*X)\n",
    "            X_prem, prem_lengths = self._prepare_dataset(X_prem)\n",
    "            X_hyp, hyp_lengths = self._prepare_dataset(X_hyp)\n",
    "            preds = self.model((X_prem, X_hyp), (prem_lengths, hyp_lengths))\n",
    "            preds = torch.softmax(preds, dim=1).cpu().numpy()\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_encoding_rnn_phi(t1, t2):\n",
    "    \"\"\"Map `t1` and `t2` to a pair of lits of leaf nodes.\"\"\"\n",
    "    if hasattr(t1, 'leaves'):\n",
    "        return (t1.leaves(), t2.leaves())\n",
    "    else:\n",
    "        return (t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_encoding_vocab(X, n_words=None):\n",
    "    wc = Counter([w for pair in X for ex in pair for w in ex])\n",
    "    wc = wc.most_common(n_words) if n_words else wc.items()\n",
    "    vocab = {w for w, c in wc}\n",
    "    vocab.add(\"$UNK\")\n",
    "    #vocab.add(glove_vec(\"UNK\"), GLOVE, is_srl=True)\n",
    "    return set(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def fit_sentence_encoding_rnn(X, y, raw_x):\n",
    "    print(\"Getting vocab\")\n",
    "    vocab = get_sentence_encoding_vocab(raw_x, n_words=10000)\n",
    "    print(\"Done getting vocab\")\n",
    "\n",
    "    mod = TorchRNNSentenceEncoderClassifier(\n",
    "        vocab, hidden_dim=50, max_iter=50, embed_dim=2 * glove_dim, use_embedding=False)\n",
    "    print(\"Fitting model\")\n",
    "    mod.fit(X, y)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "addamod_train_reader = nli.AddamodTrainReader(DATA_HOME)\n",
    "addamod_dev_reader = nli.AddamodDevReader(DATA_HOME)\n",
    "subobj_train_reader = nli.SubObjTrainReader(DATA_HOME)\n",
    "subobj_dev_reader = nli.SubObjDevReader(DATA_HOME)\n",
    "breaking_reader = nli.BreakingSNLIReader(DATA_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from allennlp.data.tokenizers.word_tokenizer import WordTokenizer\n",
    "wt = WordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def glove_srl_phi(ex, np_func=np.sum):\n",
    "    prem = build_arrays(ex.sentence1, ex.tags1, glove_lookup)\n",
    "    hyp = build_arrays(ex.sentence2, ex.tags2, glove_lookup)\n",
    "#     if type(prem) != torch.Tensor or type(hyp) != torch.Tensor:\n",
    "#         return None\n",
    "    \n",
    "    return (prem, hyp)\n",
    "\n",
    "\n",
    "def build_arrays(sentence, tags, lookup):\n",
    "    s = wt.tokenize(sentence)\n",
    "    if len(tags) != len(s):\n",
    "        print(f\"Discarding this sentence because of tag issues: {sentence}\")\n",
    "#         print(len(tags))\n",
    "#         print(len(s))\n",
    "#         print(tags)\n",
    "#         print(s)\n",
    "        combo = torch.tensor(np.concatenate(([utils.randvec(n=glove_dim) for t in tags],\n",
    "                                             [utils.randvec(n=glove_dim) for t in tags]), axis=1),\n",
    "                             dtype=torch.float32, requires_grad=False)\n",
    "    else:\n",
    "        combo = torch.cat((torch.stack([_glove_vec(w, lookup) if w in lookup else _glove_vec(\"$UNK\", lookup) for w in s]),\n",
    "                           torch.stack([_get_tag_vec(t, srl_lookup) for t in tags])), 1)\n",
    "#     if torch.cuda.is_available():\n",
    "# #         print(\"Putting embedding on cuda.\")\n",
    "#         return combo.cuda()\n",
    "#     else:\n",
    "    return combo\n",
    "    \n",
    "\n",
    "def _glove_vec(w, lookup):\n",
    "    vec = torch.tensor(lookup.get(w, lookup.get(\"$UNK\", utils.randvec(n=glove_dim))), dtype=torch.float32, requires_grad=False)\n",
    "    return vec\n",
    "    \n",
    "    \n",
    "def _get_tree_vecs(tree, lookup, np_func):\n",
    "    if hasattr(tree, 'leaves'):\n",
    "        allvecs = np.array([lookup[w] if w in lookup else lookup[\"$UNK\"] for w in tree.leaves() ])\n",
    "    else:\n",
    "        allvecs = np.array([lookup[w] if w in lookup else lookup[\"$UNK\"] for w in tree ])\n",
    "    return allvecs\n",
    "\n",
    "\n",
    "def _get_tag_vec(tag, tag_lookup):\n",
    "    if tag in tag_lookup:\n",
    "        vec = tag_lookup[tag]\n",
    "    else:\n",
    "        vec = torch.tensor(utils.randvec(n=glove_dim), dtype=torch.float32, requires_grad=True)\n",
    "        tag_lookup[tag] = vec\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell for training on SNLI, using an adversarial reader as the validation set.\n",
    "\n",
    "snli_267379 = nli.experiment(\n",
    "    train_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                               \"preprocessed_snli_1.0_train.jsonl\",\n",
    "                               samp_percentage=None), \n",
    "    phi=glove_srl_phi,\n",
    "    train_func=fit_sentence_encoding_rnn,\n",
    "    assess_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                                \"preprocessed_snli_1.0_dev.jsonl\",\n",
    "                                samp_percentage=None), \n",
    "    random_state=42,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"srl_375800.obj\", \"wb\") as fp:\n",
    "    pickle.dump(snli_267379, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"srl_267379.obj\", \"rb\") as fp:\n",
    "    snli_267379 = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this cell for using an adversarial reader as the validation set.\n",
    "\n",
    "soswap_results = nli.evaluation(\n",
    "    train_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                               \"preprocessed_snli_1.0_train.jsonl\",\n",
    "                               samp_percentage=1), \n",
    "    mod=snli_267379['model'],\n",
    "    phi=glove_srl_phi,\n",
    "    assess_reader=nli.NLIAdversaryReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                                         \"preprocessed_sub_obj_swap(dev).jsonl\",\n",
    "                                         samp_percentage=1), \n",
    "    random_state=42,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n",
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n",
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n",
      "Discarding this sentence because of tag issues: The little baseball player wearing the `` Irish '' uniform prepares to throw the ball to his teammate as the umpire watches closely .\n",
      "Discarding this sentence because of tag issues: The baseball little player wearing the `` Irish '' uniform prepares to throw the ball to his teammate as the umpire watches closely .\n",
      "Discarding this sentence because of tag issues: Many multiple people take pictures as a blond woman wearing a cover-up only costume holds a sign proclaiming `` Photographers Not Predators '' on a pier .\n",
      "Discarding this sentence because of tag issues: Many people take multiple pictures as a blond woman wearing a cover-up only costume holds a sign proclaiming `` Photographers Not Predators '' on a pier .\n",
      "Discarding this sentence because of tag issues: A brown woman with long dark hair is carrying a bag over her shoulder which says `` hot '' in metallic pink letters .\n",
      "Discarding this sentence because of tag issues: A woman with long dark brown hair is carrying a bag over her shoulder which says `` hot '' in metallic pink letters .\n",
      "Discarding this sentence because of tag issues: A gray man in a dark suit talks with a middle-aged man and woman on a stage in front of a large logo of the letter `` D '' with the numeral five within it .\n",
      "Discarding this sentence because of tag issues: A man in a dark gray suit talks with a middle-aged man and woman on a stage in front of a large logo of the letter `` D '' with the numeral five within it .\n",
      "Discarding this sentence because of tag issues: A young little boy is taking a nap underneath a piece of cardboard that reads , `` Connie Facial Tissues . ''\n",
      "Discarding this sentence because of tag issues: A young boy is taking a little nap underneath a piece of cardboard that reads , `` Connie Facial Tissues . ''\n",
      "Discarding this sentence because of tag issues: A rugby football player in a blue `` Rams '' jersey runs with a football on a field , as another player in a white jersey falls in an attempt to tackle him .\n",
      "Discarding this sentence because of tag issues: A football rugby player in a blue `` Rams '' jersey runs with a football on a field , as another player in a white jersey falls in an attempt to tackle him .\n",
      "Discarding this sentence because of tag issues: A little colored boy wearing glasses and a t-shirt that says , `` I 'm a Pepper and Dr. Pepper , '' stands looking at an older boy sitting in the grass .\n",
      "Discarding this sentence because of tag issues: A little boy wearing colored glasses and a t-shirt that says , `` I 'm a Pepper and Dr. Pepper , '' stands looking at an older boy sitting in the grass .\n",
      "Discarding this sentence because of tag issues: Two colorful children examine a stack of books and games , including the game `` Poncho Pal , '' next to a piece of furniture .\n",
      "Discarding this sentence because of tag issues: Two children examine a stack of colorful books and games , including the game `` Poncho Pal , '' next to a piece of furniture .\n",
      "Discarding this sentence because of tag issues: Several yellow people are sitting down playing volleyball with a sign that reads `` WheelPower '' in the background .\n",
      "Discarding this sentence because of tag issues: Several people are sitting down playing yellow volleyball with a sign that reads `` WheelPower '' in the background .\n",
      "Discarding this sentence because of tag issues: A strange man holds a sign outside a hotel that reads `` Ok Ok Ok , I need money for beer , pot and a hooker . ''\n",
      "Discarding this sentence because of tag issues: A man holds a strange sign outside a hotel that reads `` Ok Ok Ok , I need money for beer , pot and a hooker . ''\n",
      "Discarding this sentence because of tag issues: An elderly large woman pushing a cart filled with boxes walks by theater sign for `` South Pacific '' .\n",
      "Discarding this sentence because of tag issues: An elderly woman pushing a large cart filled with boxes walks by theater sign for `` South Pacific '' .\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.000     0.000     0.000         0\n",
      "   entailment      0.000     0.000     0.000         0\n",
      "      neutral      1.000     0.864     0.927      1783\n",
      "\n",
      "    micro avg      0.864     0.864     0.864      1783\n",
      "    macro avg      0.333     0.288     0.309      1783\n",
      " weighted avg      1.000     0.864     0.927      1783\n",
      "\n"
     ]
    }
   ],
   "source": [
    "addamod_results = nli.evaluation(\n",
    "    train_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                               \"preprocessed_snli_1.0_train.jsonl\",\n",
    "                               samp_percentage=1), \n",
    "    mod=snli_267379['model'],\n",
    "    phi=glove_srl_phi,\n",
    "    assess_reader=nli.NLIAdversaryReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                                         \"preprocessed_add_amod(dev).jsonl\",\n",
    "                                         samp_percentage=1), \n",
    "    random_state=42,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n",
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n",
      "Discarding this sentence because of tag issues: A man with a Mohawk and a shirt saying\"-ependent \"faces the camera\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:525: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.num_layers, self.dropout, self.training, self.bidirectional)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.857     0.129     0.224      6991\n",
      "   entailment      0.098     0.005     0.010       964\n",
      "      neutral      0.005     0.822     0.011        45\n",
      "\n",
      "    micro avg      0.118     0.118     0.118      8000\n",
      "    macro avg      0.320     0.319     0.081      8000\n",
      " weighted avg      0.761     0.118     0.197      8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "breaking_results = nli.evaluation(\n",
    "    train_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                               \"preprocessed_snli_1.0_train.jsonl\",\n",
    "                               samp_percentage=1), \n",
    "    mod=snli_267379['model'],\n",
    "    phi=glove_srl_phi,\n",
    "    assess_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                                         \"preprocessed_dataset.jsonl\",\n",
    "                                         samp_percentage=1), \n",
    "    random_state=42,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:525: RuntimeWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  self.num_layers, self.dropout, self.training, self.bidirectional)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "contradiction      0.314     0.005     0.010      3229\n",
      "   entailment      0.353     0.433     0.389      3361\n",
      "      neutral      0.334     0.587     0.426      3210\n",
      "\n",
      "    micro avg      0.342     0.342     0.342      9800\n",
      "    macro avg      0.334     0.341     0.275      9800\n",
      " weighted avg      0.334     0.342     0.276      9800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snli_test_results = nli.evaluation(\n",
    "    train_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                               \"preprocessed_snli_1.0_train.jsonl\",\n",
    "                               samp_percentage=0.01), \n",
    "    mod=snli_267379['model'],\n",
    "    phi=glove_srl_phi,\n",
    "    assess_reader=nli.NLIReader(\"/home/brett_szalapski/cs224uSNLI/data/nlidata/preproc_copies/\"\n",
    "                                \"preprocessed_snli_1.0_test.jsonl\",\n",
    "                                samp_percentage=None), \n",
    "    random_state=42,\n",
    "    vectorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
